
import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.log4j._


  case class ratings(userId: Int, movieID: Int, rating: Float, timestamp: String)
  case class movies(movieID: Int, movieName: String, genre:String)
  

    Logger.getLogger("Org").setLevel(Level.ERROR)


    val sc = new SparkContext("local[*]", "Joins")
    val rating = sc.textFile("chapter_5/ratings.csv").map(_.split(','))
    val movie = sc.textFile("chapter_5/movies.csv").map(_.split(','))

    val rating_record = rating.map(x => (x(1).toInt, ratings(x(0).toInt, x(1).toInt,
         x(2).toFloat, x(3).toString)))

       val movie_record = movie.map(x => (x(0).toInt, movies(x(0).toInt, x(1).toString,
         x(2).toString)))

    val joined = rating_record.join(movie_record)

    joined.collect.foreach(println)


